{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN)\n",
    "\n",
    "I am using a CNN written in `tensorflow` and `keras`. CNN is a class of neural networks commonly applied to image data for image classification. In this technique, the image is divided into subgrids, and these subgrids are passed on the entire image. The passing of these subgrids is called convolution. In each convolution, the model is learning features that occupy that space at a higher level. In other words, in each convolution, the model passes the subgrids on the entire image and learns general features across the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YhKx2r7XUezO"
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# unzip /content/drive/MyDrive/TDI_Capstone_Project/partial_dataset.zipb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7087,
     "status": "ok",
     "timestamp": 1612137237748,
     "user": {
      "displayName": "Nathalia Graf Grachet",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_Bik6IV8ChA52x-9XMwDtfEKXydH3vJkY51LI=s64",
      "userId": "00014870134813344372"
     },
     "user_tz": 420
    },
    "id": "dHJwACbVUa_y",
    "outputId": "ff6ee2dd-269c-482d-c4ed-5fec2c62d2c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.4.1\n",
      "Keras version: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "from natsort import natsorted\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 697,
     "status": "ok",
     "timestamp": 1612137275152,
     "user": {
      "displayName": "Nathalia Graf Grachet",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_Bik6IV8ChA52x-9XMwDtfEKXydH3vJkY51LI=s64",
      "userId": "00014870134813344372"
     },
     "user_tz": 420
    },
    "id": "tteLpeIPydkw",
    "outputId": "e56a8394-4345-419a-8d3c-606bcffcb7ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 5, 5, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_images = pd.read_csv('partial_dataset/train/labels_images.csv')\n",
    "labels_images.rename(columns={'0':'labels'}, inplace=True)\n",
    "labels = labels_images['labels'].to_numpy() - 1  # to be in range(0,6)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 375,
     "status": "ok",
     "timestamp": 1612137276559,
     "user": {
      "displayName": "Nathalia Graf Grachet",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_Bik6IV8ChA52x-9XMwDtfEKXydH3vJkY51LI=s64",
      "userId": "00014870134813344372"
     },
     "user_tz": 420
    },
    "id": "2fEUtYntydr0",
    "outputId": "f37c64ff-af33-487f-f0f9-5cdbb1d728da",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['partial_dataset/train/images/18X67NLZ2_707-1603-1219-2115.jpg',\n",
       " 'partial_dataset/train/images/18X67NLZ2_1219-579-1731-1091.jpg',\n",
       " 'partial_dataset/train/images/18X67NLZ2_1219-1091-1731-1603.jpg',\n",
       " 'partial_dataset/train/images/18X67NLZ2_1219-1603-1731-2115.jpg',\n",
       " 'partial_dataset/train/images/26G8P9NJF_576-4531-1088-5043.jpg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 - get list of paths\n",
    "list_images = [f\"partial_dataset/train/images/{x}\" for x in labels_images['filename'].to_list()]\n",
    "list_images[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 437,
     "status": "ok",
     "timestamp": 1612137278630,
     "user": {
      "displayName": "Nathalia Graf Grachet",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_Bik6IV8ChA52x-9XMwDtfEKXydH3vJkY51LI=s64",
      "userId": "00014870134813344372"
     },
     "user_tz": 420
    },
    "id": "gs9lMQi_itbG"
   },
   "outputs": [],
   "source": [
    "# 2 - function to read each image into np.array\n",
    "\n",
    "def read_image(data_x):\n",
    "    \"\"\"Read obj with the path for images.\n",
    "    data_x ==  *_x\n",
    "    \"\"\"\n",
    "\n",
    "    W, H = 300, 300 # set final size\n",
    "\n",
    "    x = cv2.imread(data_x, cv2.IMREAD_COLOR) # read in colors\n",
    "    x = cv2.resize(x, (W, H)) # resize\n",
    "    x = x / 255.0 # normalize values 0 to 1\n",
    "    x = x.astype(np.float32) # make it np.float32\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 68522,
     "status": "ok",
     "timestamp": 1612137359634,
     "user": {
      "displayName": "Nathalia Graf Grachet",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_Bik6IV8ChA52x-9XMwDtfEKXydH3vJkY51LI=s64",
      "userId": "00014870134813344372"
     },
     "user_tz": 420
    },
    "id": "NRtCVibmydvk"
   },
   "outputs": [],
   "source": [
    "# 3 - get an array of images\n",
    "images = np.array([read_image(x) for x in list_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1889,
     "status": "ok",
     "timestamp": 1612137378784,
     "user": {
      "displayName": "Nathalia Graf Grachet",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_Bik6IV8ChA52x-9XMwDtfEKXydH3vJkY51LI=s64",
      "userId": "00014870134813344372"
     },
     "user_tz": 420
    },
    "id": "BmHC2UPeywiG",
    "outputId": "9d1632d3-c56c-4422-caa4-99762b6df63c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 2828, Train labels: 2828, Test images: 1886, Test labels: 1886\n"
     ]
    }
   ],
   "source": [
    "# 4 - split labels and images into train and test\n",
    "train_images, test_images = train_test_split(images, test_size=0.4, random_state=88)\n",
    "train_labels, test_labels = train_test_split(labels, test_size=0.4, random_state=88)\n",
    "\n",
    "print(\n",
    "    f\"Train images: {len(train_images)}, Train labels: {len(train_labels)}, Test images: {len(test_images)}, Test labels: {len(test_labels)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 661,
     "status": "ok",
     "timestamp": 1612137380880,
     "user": {
      "displayName": "Nathalia Graf Grachet",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_Bik6IV8ChA52x-9XMwDtfEKXydH3vJkY51LI=s64",
      "userId": "00014870134813344372"
     },
     "user_tz": 420
    },
    "id": "q-Kfwh5fmUx2",
    "outputId": "17bcdfff-c527-494d-f30e-b50fc1b97074"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(2828, 300, 300, 3) (2828,)\n"
     ]
    }
   ],
   "source": [
    "# check data type and shape\n",
    "print(type(train_images), type(train_labels))\n",
    "print(train_images.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 538,
     "status": "ok",
     "timestamp": 1612137383876,
     "user": {
      "displayName": "Nathalia Graf Grachet",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_Bik6IV8ChA52x-9XMwDtfEKXydH3vJkY51LI=s64",
      "userId": "00014870134813344372"
     },
     "user_tz": 420
    },
    "id": "g5s7V88HzL2T",
    "outputId": "4c6a5f71-04a7-4161-cf3d-8dbfaf28072c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(1886, 300, 300, 3) (1886,)\n"
     ]
    }
   ],
   "source": [
    "# check data type and shape\n",
    "print(type(test_images), type(test_labels))\n",
    "print(test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "noIm21iJznvK",
    "outputId": "3cd7f05b-a17b-4643-ceb3-5af972c51a6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "36/36 [==============================] - 21s 435ms/step - loss: 1.2422 - accuracy: 0.6002\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 11s 314ms/step - loss: 1.0602 - accuracy: 0.6632\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 11s 295ms/step - loss: 1.0041 - accuracy: 0.6663\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 11s 298ms/step - loss: 0.9228 - accuracy: 0.6761\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 12s 325ms/step - loss: 0.8843 - accuracy: 0.6790\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 11s 315ms/step - loss: 0.8621 - accuracy: 0.6865\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 11s 292ms/step - loss: 0.8226 - accuracy: 0.6950\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 10s 283ms/step - loss: 0.7541 - accuracy: 0.7239\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 10s 279ms/step - loss: 0.7527 - accuracy: 0.7474\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 11s 294ms/step - loss: 0.6985 - accuracy: 0.7419\n",
      "Accuracy on test data is 72.06%\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "        keras.layers.AveragePooling2D(pool_size=6, strides=6, input_shape=(300, 300, 3)),\n",
    "        keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "        keras.layers.Conv2D(32, 2, activation='relu'),\n",
    "        keras.layers.MaxPool2D(3, 3),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=80)\n",
    "\n",
    "acc = round(model.evaluate(test_images, test_labels, verbose=0)[1], 4)*100\n",
    "print(f\"Accuracy on test data is {acc}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WIY4hXjAkZ6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_1_CNN/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./model_1_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPqlUUqBSJ6BCzXyIqlL1Bp",
   "collapsed_sections": [],
   "mount_file_id": "1n88rHExDV4EJtUzW--DPBfVy6xjGpX9n",
   "name": "TDI_Semantic_Segmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
